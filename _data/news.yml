
- item: Our paper on using interpretability to understand why Language Model's struggle with negation accepted at the ACL RepL4NLP workshop 2023 
  date: 2023-07-09

- item: Completed my time at Millennium Management as the first Quantitative Research intern in India, where I worked on AutoML for trading.
  date: 2023-07-23

- item: Granted funding to continue my work with the Center for AI Safety through the SERI MATS program, after my 2 month research visit at Berkeley, California 
  date: 2023-09-01

- item: <b>Outstanding Paper Award at AAAI 2024</b> for our paper <a href="https://arxiv.org/abs/2306.14858">Proportional Aggregation of Preferences for Sequential Decision Making</a>
  date: 2024-02-23
  
- item: Recognized as an Exceptional Reviewer at the ICLR Data-Centric ML Workshop
  date: 2024-04-10

- item: Our paper <a href="https://arxiv.org/abs/2403.03218">The WMDP Benchmark:Measuring and Reducing Malicious with Unlearning</a> accepted at ICML 2024
  date: 2024-05-01

- item: Defended my masters thesis on <em>New Frontiers for Machine Unlearning</em> at IIIT Hyderabad
  date: 2024-05-24

- item: Starting a PhD in TÃ¼bingen (Germany), co-advised by Jonas Geiping (ELLIS, MPI-IS) and Douwe Kiela (Contextual AI, Stanford)
  date: 2024-09-02

- item: Our paper <a href="https://arxiv.org/abs/2402.14015">Corrective Machine Unlearning</a> accepted at TMLR
  date: 2024-10-13

- item: First paper of my PhD <a href="https://arxiv.org/abs/2502.04313">Great Models Think Alike and this Undermines AI Oversight</a> is out on ArXiv
  date: 2025-02-06

